[{"name":"app.R","content":"library(shiny)\r\nlibrary(dplyr)\r\nlibrary(reactable)\r\nlibrary(bslib)\r\nlibrary(haven)\r\n\r\n# Source the helper functions\r\nsource(\"nsse.R\")\r\nsource(\"functions.R\")\r\nsource(\"ui.R\")\r\n\r\n# Server logic\r\nserver <- function(input, output, session) {\r\n  data <- reactiveVal()\r\n  careless_results <- reactiveVal()\r\n  \r\n  # Add popups after survey selection\r\n  observeEvent(input$surveySelect, {\r\n    if (input$surveySelect != \"Click here for options\") {\r\n      show_upload_instructions(session)\r\n    }\r\n    \r\n    # Conditionally source files based on survey selection\r\n    # if (input$surveySelect == \"Fake Study\") {\r\n    #   source(\"fake study.R\", local = TRUE)\r\n    #   # Optionally, remove the other source from memory if needed\r\n    #   # rm(list = ls(envir = .GlobalEnv, pattern = \"nsse\"), envir = .GlobalEnv)\r\n  #}\r\n     else if (input$surveySelect == \"NSSE\") {\r\n      source(\"nsse.R\", local = TRUE)\r\n      # Optionally, remove the other source from memory if needed\r\n      # rm(list = ls(envir = .GlobalEnv, pattern = \"fake\"), envir = .GlobalEnv)\r\n    }\r\n  })\r\n  \r\n  \r\n  \r\n  observeEvent(input$run, {\r\n    req(input$file)\r\n    \r\n    # Read the uploaded file\r\n    df <- read_uploaded_file(input$file)\r\n    \r\n    # Check for missing variables\r\n    missing_vars <- check_missing_vars(df)\r\n    \r\n    # Show screen if any variables are missing\r\n    if (length(missing_vars) > 0) {\r\n      showModal(show_missing_vars_modal(missing_vars))\r\n    }\r\n  })\r\n  \r\n  observeEvent(input$run, {\r\n    req(input$file)\r\n    \r\n    # Remove recoded or estimated variables not used in the analysis\r\n    df <- remove_recoded_vars(df)\r\n    \r\n    # Clean the uploaded data\r\n    df <- clean_data(df)\r\n    \r\n    # Identify careless responses - now stores results in reactive value\r\n    results <- identify_careless_responses(df)\r\n    careless_results(results)\r\n    \r\n    # Process the summary table data using the new results structure\r\n    summary_df <- calculate_summary(\r\n      results$data, \r\n      results$flags, \r\n      results$step_results\r\n    )\r\n    data(summary_df)\r\n    \r\n    # Let user know analysis is complete\r\n    output$analysisCompleteOverview <- renderUI({\r\n      create_analysis_complete_message()\r\n    })\r\n    \r\n    output$analysisComplete <- renderUI({\r\n      create_analysis_complete_message()\r\n    })\r\n    \r\n    output$summaryText <- renderText({\r\n      create_summary_text(data())\r\n    })\r\n    \r\n    output$summaryTable <- renderReactable({\r\n      req(data())\r\n      create_summary_table(data())\r\n    })\r\n    \r\n    get_survey_prefix <- function(survey_selection) {\r\n      switch(survey_selection,\r\n             \"National Survey of Student Engagement (NSSE)\" = \"nsse\",\r\n             \"survey\"\r\n      )\r\n    }\r\n    \r\n    output$downloadData <- downloadHandler(\r\n      filename = function() {\r\n        survey_prefix <- get_survey_prefix(input$surveySelect)\r\n        paste(survey_prefix, \"_survey_low_effort_responses_\", Sys.Date(), \".xlsx\", sep = \"\")\r\n      },\r\n      content = function(file) {\r\n        results <- careless_results()\r\n        \r\n        new_wb <- createWorkbook()\r\n        header_style <- createStyle(textDecoration = \"bold\", fontSize = 12)\r\n        text_style <- createStyle(fontSize = 12, wrapText = TRUE)\r\n        bullet_style <- createStyle(fontSize = 12, wrapText = TRUE, indent = 1)\r\n        \r\n        addWorksheet(new_wb, \"About\")\r\n        about_text <- c(\r\n          \"This Excel file has your data and results from the 'Detecting Low Effort Surveys' tool. It contains the following sheets:\",\r\n          \"\",\r\n          \"1. 'Your Summary': A table displaying the frequency (and percentage) of how often respondents exhibited behaviors indicating low-effort responding.\",\r\n          \"2. 'Your Data': Your data with additional columns indicating which responses were considered 'low effort' based on violating at least one of the criteria examined. These are responses that you may wish to consider removing from future analyses.\",\r\n          \"\",\r\n          \"If you have any questions, please contact Steve at stevensherrin@gmail.com with the title 'Detecting Low Effort Surveys'.\"\r\n        )\r\n        writeData(new_wb, \"About\", about_text, startCol = 1, startRow = 1)\r\n        addStyle(new_wb, \"About\", header_style, rows = 1, cols = 1)\r\n        addStyle(new_wb, \"About\", text_style, rows = 2:2, cols = 1, gridExpand = TRUE)\r\n        addStyle(new_wb, \"About\", bullet_style, rows = 3:5, cols = 1, gridExpand = TRUE)\r\n        addStyle(new_wb, \"About\", text_style, rows = 6:6, cols = 1, gridExpand = TRUE)\r\n        setColWidths(new_wb, \"About\", cols = 1, widths = 100)\r\n        \r\n        addWorksheet(new_wb, \"Your Summary\")\r\n        writeData(new_wb, \"Your Summary\", data())\r\n        for (col in 1:ncol(data())) {\r\n          setColWidths(new_wb, \"Your Summary\", cols = col, widths = \"auto\")\r\n        }\r\n        addStyle(new_wb, \"Your Summary\", header_style, rows = 1, cols = 1:ncol(data()), gridExpand = TRUE)\r\n        \r\n        last_row <- nrow(data()) + 1\r\n        last_row_style <- createStyle(fgFill = \"black\", fontColour = \"white\")\r\n        addStyle(new_wb, \"Your Summary\", last_row_style, rows = last_row, cols = 1:ncol(data()), gridExpand = TRUE)\r\n        \r\n        addWorksheet(new_wb, \"Your Data\")\r\n        df2 <- results$data\r\n        df2 <- df2 %>% \r\n          rename(`Row # in Original Data` = unique_id) %>%\r\n          select(`Row # in Original Data`, everything())\r\n        writeData(new_wb, \"Your Data\", df2)\r\n        \r\n        saveWorkbook(new_wb, file, overwrite = TRUE)\r\n      }\r\n    )\r\n  })\r\n}\r\n\r\n# Run the application \r\nshinyApp(ui = ui, server = server)\r\n","type":"text"},{"name":"ui.R","content":"library(shiny)\r\nlibrary(bslib)\r\n\r\n# Downloading issue in Chrome. Workaround for Chromium Issue 468227\r\ndownloadButton <- function(...) {\r\n  tag <- shiny::downloadButton(...)\r\n  tag$attribs$download <- NULL\r\n  tag\r\n}\r\n\r\n# Function to show missing variables modal\r\nshow_missing_vars_modal <- function(missing_vars) {\r\n  modalDialog(\r\n    title = \"Note About Missing Variables\",\r\n    HTML(paste0(\r\n      \"<p>The following variables are not present in your data: <br><br>\",\r\n      \"<strong>\", paste(missing_vars, collapse = \", \"), \"<\/strong><\/p>\",\r\n      \"<p>This is common and may occur for a couple reasons:<\/p>\",\r\n      \"<ul>\",\r\n      \"<li>You're using data from a historical version of the survey when these questions weren't included<\/li>\",\r\n      \"<li>Variable names changed across survey years<\/li>\",\r\n      \"<\/ul>\",\r\n      \"<p>The analysis will still run, but some checks may be limited to the variables that are present in your data.<\/p>\"\r\n    )),\r\n    easyClose = TRUE,\r\n    footer = modalButton(\"OK\")\r\n  )\r\n}\r\n\r\n# Function for analysis complete message\r\ncreate_analysis_complete_message <- function() {\r\n  HTML('\r\n    <div style=\"\r\n      background: #007BFF;\r\n      color: white;\r\n      padding: 20px;\r\n      border-radius: 10px;\r\n      box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);\r\n      margin: 20px 0;\r\n      animation: fadeInUp 0.5s ease-out;\r\n    \">\r\n      <div style=\"display: flex; align-items: center;\">\r\n        <span style=\"font-size: 24px; margin-right: 15px;\">‚úÖ<\/span>\r\n        <div>\r\n          <h3 style=\"margin: 0; font-size: 20px; font-weight: bold;\">Analysis Successfully Completed!<\/h3>\r\n          <p style=\"margin: 10px 0 0 0; font-size: 16px;\">Your data has been processed and is ready to review. Here\\'s what you can do next:<\/p>\r\n          <ul style=\"margin: 10px 0 0 0; padding-left: 20px;\">\r\n            <li>Go to <strong>Summary<\/strong> to see an overview of your results<\/li>\r\n            <li>Use <strong>Download Data<\/strong> to export your analyzed dataset<\/li>\r\n          <\/ul>\r\n        <\/div>\r\n      <\/div>\r\n    <\/div>\r\n    <style>\r\n      @keyframes fadeInUp {\r\n        from {\r\n          opacity: 0;\r\n          transform: translateY(20px);\r\n        }\r\n        to {\r\n          opacity: 1;\r\n          transform: translateY(0);\r\n        }\r\n      }\r\n    <\/style>\r\n  ')\r\n}\r\n\r\n# Function for summary text\r\ncreate_summary_text <- function(data) {\r\n  all_responses <- data$`Remaining Unflagged Responses`[1]\r\n  final_valid <- tail(data$`Remaining Unflagged Responses`, 1)\r\n  total_removed <- tail(data$`Responses Flagged in this Step`, 1)\r\n  percent_removed <- total_removed / all_responses * 100\r\n  \r\n  paste0(\r\n    \"You started with <b style='text-decoration: underline double;'>\", all_responses, \r\n    \"<\/b> respondents. After searching for several criteria, we flagged <b style='text-decoration: underline double;'>\", \r\n    total_removed, \"<\/b>  responses that potentially indicate low effort (<b style='text-decoration: underline double;'>\", \r\n    round(percent_removed, 1), \"% of total<\/b>). For details on the specific issues found, see the table below. For methodology details, see About.\"\r\n  )\r\n}\r\n\r\n# Create summary table configuration\r\ncreate_summary_table <- function(data) {\r\n  reactable(\r\n    data,\r\n    defaultPageSize = nrow(data), # Show all rows\r\n    columns = list(\r\n      `Step Description` = colDef(\r\n        name = \"\",\r\n        cell = function(value) {\r\n          div(style = list(fontStyle = \"italic\"), value)\r\n        },\r\n        headerStyle = list(verticalAlign = \"top\"),\r\n        minWidth = 350,\r\n        maxWidth = 350\r\n      ),\r\n      `Remaining Unflagged Responses` = colDef(\r\n        name = \"Remaining Unflagged Responses\",\r\n        headerStyle = list(textAlign = \"center\"),\r\n        style = list(textAlign = \"center\"),\r\n        minWidth = 150,\r\n        maxWidth = 150\r\n      ),\r\n      `Responses Flagged in this Step` = colDef(\r\n        name = \"Responses Flagged in this Step\",\r\n        headerStyle = list(textAlign = \"center\"),\r\n        style = list(textAlign = \"center\"),\r\n        minWidth = 150,\r\n        maxWidth = 150\r\n      ),\r\n      `Percent of All Responses Flagged in this Step` = colDef(\r\n        name = \"Percent of All Responses Flagged in this Step\",\r\n        headerStyle = list(textAlign = \"center\"),\r\n        format = colFormat(percent = TRUE, digits = 1),\r\n        style = list(textAlign = \"center\"),\r\n        minWidth = 150,\r\n        maxWidth = 150\r\n      ),\r\n      `Total Responses Flagged for this Issue` = colDef(\r\n        name = \"Total Responses with this Issue\",\r\n        headerStyle = list(textAlign = \"center\"),\r\n        style = list(textAlign = \"center\"),\r\n        minWidth = 150,\r\n        maxWidth = 150\r\n      ),\r\n      `Percent of All Responses with this Issue` = colDef(\r\n        name = \"Percent of All Responses with this Issue\",\r\n        headerStyle = list(textAlign = \"center\"),\r\n        style = list(textAlign = \"center\"),\r\n        minWidth = 150,\r\n        maxWidth = 150\r\n      )\r\n    ),\r\n    rowStyle = function(index) {\r\n      if (index == 1) {\r\n        list(\r\n          fontWeight = \"bold\",\r\n          background = \"#f7f7f7\"\r\n        )\r\n      } else if (index == nrow(data)) {\r\n        list(\r\n          background = \"darkred\",\r\n          color = \"white\",\r\n          fontWeight = \"bold\",\r\n          border = \"2px solid #cc0000\"\r\n        )\r\n      } else {\r\n        NULL\r\n      }\r\n    }\r\n  )\r\n}\r\n\r\n# Function to show missing variables modal\r\nshow_missing_vars_modal <- function(missing_vars) {\r\n  modalDialog(\r\n    title = \"Note About Missing Variables\",\r\n    HTML(paste0(\r\n      \"<p>The following variables are not present in your data: <br><br>\",\r\n      \"<strong>\", paste(missing_vars, collapse = \", \"), \"<\/strong><\/p>\",\r\n      \"<p>This is common and may occur for a couple reasons:<\/p>\",\r\n      \"<ul>\",\r\n      \"<li>You're using data from a historical version of the survey when these questions weren't included<\/li>\",\r\n      \"<li>Variable names changed across survey years<\/li>\",\r\n      \"<\/ul>\",\r\n      \"<p>The analysis will still run, but some checks may be limited to the variables that are present in your data.<\/p>\"\r\n    )),\r\n    easyClose = TRUE,\r\n    footer = modalButton(\"OK\")\r\n  )\r\n}\r\n\r\n# Format summary table\r\nformat_percentage_cell <- function(value) {\r\n  value <- min(max(value, 0), 1)\r\n  gradientValue <- scales::rescale(value, c(0, 1), c(0, 1))\r\n  color <- colorRampPalette(c(\"white\", \"red\"))(100)[as.integer(gradientValue * 99) + 1]\r\n  style <- paste(\"background-color:\", color, \"; color: black;\")\r\n  htmltools::span(style = style, scales::percent(value, accuracy = 0.1))\r\n}\r\n\r\n# UI\r\nui <- fluidPage(\r\n  theme = bslib::bs_theme(\r\n    primary = \"#007BFF\",\r\n    secondary = \"#6C757D\"\r\n  ),\r\n  tags$head(\r\n    tags$style(HTML(\"\r\n      .shiny-input-container {  \r\n        font-family: 'IBM Plex Sans', sans-serif;\r\n      }\r\n      .icon {\r\n        font-size: 24px;\r\n        vertical-align: middle;\r\n        margin-right: 10px;\r\n      }\r\n      .footer {\r\n        font-size: 12px;\r\n        color: #6C757D;\r\n        margin-top: 20px;\r\n        text-align: right;\r\n      }\r\n      .header {\r\n        display: flex;\r\n        align-items: center;\r\n        margin-bottom: 20px;\r\n      }\r\n      .header img {\r\n        margin-right: 10px;\r\n      }\r\n      .safety-icon {\r\n        font-size: 24px;\r\n        color: #28a745;\r\n        vertical-align: middle;\r\n        margin-right: 10px;\r\n      }\r\n      .overview-icon {\r\n        font-size: 24px;\r\n        color: #007BFF;\r\n        vertical-align: middle;\r\n        margin-right: 10px;\r\n      }\r\n      .main-title {\r\n        font-size: 36px;\r\n        font-weight: bold;\r\n        text-align: left;\r\n        margin-bottom: 20px;\r\n      }\r\n    \"))\r\n  ),\r\n  \r\n  # Main header with the title\r\n  div(\r\n    class = \"header\",\r\n    div(\r\n      style = \"\r\n      background: #007BFF;\r\n      padding: 20px;\r\n      border-radius: 10px;\r\n      display: inline-block;\r\n      box-shadow: 0 2px 4px rgba(0,0,0,0.1);\r\n    \",\r\n      div(\r\n        style = \"display: flex; align-items: center; gap: 15px;\",\r\n        # Icon container\r\n        span(\r\n          style = \"\r\n          font-size: 32px;\r\n          background: white;\r\n          color: #007BFF;\r\n          width: 50px;\r\n          height: 50px;\r\n          display: flex;\r\n          align-items: center;\r\n          justify-content: center;\r\n          border-radius: 10px;\r\n        \",\r\n          \"üìä\"\r\n        ),\r\n        # Title text\r\n        h1(\r\n          style = \"\r\n          font-family: 'IBM Plex Sans', sans-serif;\r\n          color: white;\r\n          font-weight: bold;\r\n          font-size: 28px;\r\n          margin: 0;\r\n          line-height: 1.2;\r\n        \",\r\n          \"Detecting Low-Effort\",\r\n          br(),\r\n          \"IR Survey Responses\")\r\n      )\r\n    )\r\n  ),\r\n  \r\n  sidebarLayout(\r\n    sidebarPanel(\r\n      selectInput(\"surveySelect\", \"Select your survey\", \r\n                  choices = c(\"Click here for options\" = \"Click here for options\",\r\n                              #\"Fake Study\" = \"Fake Study\",\r\n                              \"NSSE\" = \"National Survey of Student Engagement (NSSE)\")),\r\n      fileInput(\"file\", \"Upload the raw data file (e.g. .csv, .xlsx):\"),\r\n      actionButton(\"run\", \"Run\")\r\n    ),\r\n    mainPanel(\r\n      tabsetPanel(\r\n        # Overview tab\r\n        tabPanel(\"Overview\",\r\n                 div(\r\n                   style = \"padding: 20px; max-width: 1000px; margin: 0 auto;\",\r\n                   \r\n                   # Analysis Complete Message (when present)\r\n                   uiOutput(\"analysisCompleteOverview\"),\r\n                   \r\n                   # Welcome Section\r\n                   div(\r\n                     style = \"\r\n    background: #f8f9fa;\r\n    color: #2C3E50;\r\n    padding: 25px;\r\n    border: 1px solid #e0e0e0;\r\n    border-radius: 10px;\r\n    margin-bottom: 30px;\r\n  \",\r\n                     h2(style = \"margin: 0 0 15px 0; font-size: 24px; color: #007BFF;\", \r\n                        \"Welcome to the IR Low-Effort Survey Response Detector\")\r\n                   ),\r\n                   \r\n                   # Main Features\r\n                   div(\r\n                     style = \"\r\n        display: grid;\r\n        grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));\r\n        gap: 20px;\r\n        margin-bottom: 30px;\r\n      \",\r\n                     \r\n                     # What It Does\r\n                     div(\r\n                       style = \"\r\n          background: white;\r\n          padding: 20px;\r\n          border-radius: 10px;\r\n          border: 1px solid #e0e0e0;\r\n        \",\r\n                       div(style = \"display: flex; align-items: center; margin-bottom: 15px;\",\r\n                           span(class = \"overview-icon\", style = \"font-size: 24px;\", \"üìä\"),\r\n                           h3(style = \"color: #007BFF; margin: 0 0 0 10px;\", \"What It Does\")\r\n                       ),\r\n                       p(style = \"margin: 0; line-height: 1.6;\",\r\n                         \"Automatically screens your IR survey responses for behavior that might indicate low-effort responses.\")\r\n                     ),\r\n                     \r\n                     # Data Privacy\r\n                     div(\r\n                       style = \"\r\n    background: white;\r\n    padding: 20px;\r\n    border-radius: 10px;\r\n    border: 1px solid #e0e0e0;\r\n  \",\r\n                       div(\r\n                         style = \"display: flex; align-items: center; margin-bottom: 15px;\",\r\n                         span(class = \"safety-icon\", style = \"font-size: 24px;\", \"üîí\"),\r\n                         h3(style = \"color: #007BFF; margin: 0 0 0 10px;\", \"Data Privacy\")\r\n                       ),\r\n                       p(\r\n                         style = \"margin: 0; line-height: 1.6;\",\r\n                         \"Your data stays on your computer. Using \", \r\n                         a(\r\n                           href = \"https://posit-dev.github.io/r-shinylive/\",\r\n                           target = \"_blank\",\r\n                           \"ShinyLive\",\r\n                           style = \"color: #007BFF; text-decoration: none;\"\r\n                         ),\r\n                         \", a new tool for the R language, everything runs locally in your browser with no external servers involved.\"\r\n                       )\r\n                     )\r\n                   ),\r\n                   \r\n                   # Getting Started\r\n                   div(\r\n                     style = \"\r\n        background: white;\r\n        padding: 25px;\r\n        border-radius: 10px;\r\n        border: 1px solid #e0e0e0;\r\n      \",\r\n                     div(style = \"display: flex; align-items: center; margin-bottom: 15px;\",\r\n                         span(style = \"font-size: 24px;\", \"üöÄ\"),\r\n                         h3(style = \"color: #007BFF; margin: 0 0 0 10px;\", \"Getting Started\")\r\n                     ),\r\n                     div(\r\n                       style = \"\r\n          background: #f8f9fa;\r\n          padding: 20px;\r\n          border-radius: 8px;\r\n          line-height: 1.6;\r\n        \",\r\n                       HTML(\"\r\n          <ol style='margin: 0; padding-left: 20px;'>\r\n            <li>Select your survey type from the dropdown menu<\/li>\r\n            <li>Upload your raw data file (e.g. .csv, .xlsx, .sav format)<\/li>\r\n            <li>Click 'Run' to begin the analysis<\/li>\r\n          <\/ol>\r\n        \")\r\n                     )\r\n                   )\r\n                 )\r\n        ),\r\n        tabPanel(\"Summary\",\r\n                 tags$div(\r\n                   tags$br(),\r\n                   \r\n                   # Analysis Summary at the top\r\n                   tags$div(\r\n                     style = \"background-color: #e8f4f8; padding: 20px; border-radius: 5px; margin-bottom: 30px;\",\r\n                     tags$h4(style = \"color: #2C3E50; margin-bottom: 15px;\", \r\n                             \"Analysis Summary\"),\r\n                     tags$p(style = \"font-size: 16px; line-height: 1.6;\", \r\n                            uiOutput(\"summaryText\"))\r\n                   ),\r\n                   \r\n                   # Add the React component here\r\n                   tags$div(\r\n                     id = \"summary-explanation\",\r\n                     tags$div(class = \"summary-explanation-container\")\r\n                   ),\r\n                   \r\n                   # Summary Table\r\n                   tags$h3(style = \"font-weight: bold;\", \"Summary Table\"),\r\n                   reactableOutput(\"summaryTable\")\r\n                 )\r\n        ),\r\n        \r\n        # \"Download Data\" tab\r\n        tabPanel(\"Download Data\",\r\n                 div(\r\n                   style = \"padding: 20px; max-width: 1200px; margin: 0 auto;\",\r\n                   \r\n                   # Download Section at Top\r\n                   div(\r\n                     style = \"\r\n        background: #007BFF;\r\n        color: white;\r\n        padding: 25px;\r\n        border-radius: 10px;\r\n        margin-bottom: 30px;\r\n        text-align: center;\r\n        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);\r\n      \",\r\n                     h2(style = \"margin: 0 0 15px 0; font-size: 24px;\", \"Download Your Analysis Results\"),\r\n                     downloadButton(\"downloadData\", \"Download Excel File\", \r\n                                    style = \"\r\n          font-size: 16px;\r\n          padding: 12px 24px;\r\n          background-color: white;\r\n          color: #007BFF;\r\n          border: none;\r\n          font-weight: bold;\r\n        \"\r\n                     ),\r\n                     p(style = \"margin: 15px 0 0 0; font-size: 14px; opacity: 0.9;\",\r\n                       \"File will be saved as 'nsse_survey_low_effort_responses_[DATE].xlsx'\")\r\n                   ),\r\n                   \r\n                   # What's Included Section - Simplified\r\n                   div(\r\n                     style = \"\r\n        background: white;\r\n        padding: 25px;\r\n        border-radius: 10px;\r\n        border: 1px solid #e0e0e0;\r\n      \",\r\n                     h3(style = \"color: #007BFF; margin-top: 0;\", \"What's Included in Your Download\"),\r\n                     \r\n                     div(\r\n                       style = \"display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); gap: 20px; margin-top: 15px;\",\r\n                       \r\n                       # About Sheet\r\n                       div(\r\n                         style = \"padding: 15px; background: #f8f9fa; border-radius: 8px;\",\r\n                         h4(style = \"color: #666; margin: 0 0 10px 0;\", \"üìù About Sheet\"),\r\n                         p(style = \"margin: 0; color: #666;\", \"Overview of file contents and interpretation guide\")\r\n                       ),\r\n                       \r\n                       # Summary Sheet\r\n                       div(\r\n                         style = \"padding: 15px; background: #f8f9fa; border-radius: 8px;\",\r\n                         h4(style = \"color: #666; margin: 0 0 10px 0;\", \"üìä Summary Sheet\"),\r\n                         p(style = \"margin: 0; color: #666;\", \"Analysis results showing flagged responses at each step\")\r\n                       ),\r\n                       \r\n                       # Data Sheet\r\n                       div(\r\n                         style = \"padding: 15px; background: #f8f9fa; border-radius: 8px;\",\r\n                         h4(style = \"color: #666; margin: 0 0 10px 0;\", \"üíæ Data Sheet\"),\r\n                         p(style = \"margin: 0; color: #666;\", \"Your dataset with new columns indicating flagged responses\")\r\n                       )\r\n                     )\r\n                   )\r\n                 )\r\n        ),\r\n        tabPanel(\"About\",\r\n                 div(\r\n                   style = \"padding: 20px; max-width: 1000px; margin: 0 auto;\",\r\n                   \r\n                   # Main Content\r\n                   div(\r\n                     style = \"\r\n        background: white;\r\n        padding: 25px;\r\n        border-radius: 10px;\r\n        border: 1px solid #e0e0e0;\r\n        margin-bottom: 30px;\r\n      \",\r\n                     h3(style = \"color: #007BFF; margin-top: 0;\", \"How It Works\"),\r\n                     p(style = \"line-height: 1.6;\",\r\n                       \"Our tool employs a sequential approach to identify respondents whose behavior may indicate low-effort responses. Responses pass through filters one by one, with flagged responses excluded from subsequent steps. The filters are prioritized based on the severity of the violation, starting with the most serious issues.\"),\r\n                     \r\n                     div(\r\n                       style = \"\r\n          background: #f8f9fa;\r\n          padding: 20px;\r\n          border-radius: 8px;\r\n          margin: 15px 0;\r\n        \",\r\n                       HTML(\"\r\n          <p style='margin: 0 0 15px 0;'><strong>Methodology:<\/strong><\/p>\r\n          <ol style='margin: 0; padding-left: 20px; line-height: 1.6;'>\r\n            <li>Each step focuses on a specific pattern of low-effort responding.<\/li>\r\n            <li>Flagged responses are removed before proceeding to the next check.<\/li>\r\n          <\/ol>\r\n        \")\r\n                     )\r\n                   ),\r\n                   \r\n                   # Additional Resources\r\n                   div(\r\n                     style = \"\r\n        display: grid;\r\n        grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));\r\n        gap: 20px;\r\n        margin-bottom: 30px;\r\n      \",\r\n                     \r\n                     # Documentation Link\r\n                     div(\r\n                       style = \"\r\n          background: #f8f9fa;\r\n          padding: 20px;\r\n          border-radius: 8px;\r\n          border: 1px solid #e0e0e0;\r\n        \",\r\n                       h4(style = \"color: #007BFF; margin-top: 0;\", \"üìö Documentation\"),\r\n                       p(style = \"line-height: 1.6;\", \r\n                         \"For detailed methodology and research background, visit our \",\r\n                         a(href = \"https://github.com/stevensherrin/IR-Low-Effort-Survey-Responses-App/tree/main/supporting%20materials\",\r\n                           target = \"_blank\",\r\n                           \"documentation page\", \r\n                           style = \"color: #007BFF; text-decoration: none;\")\r\n                       )\r\n                     ),\r\n                     \r\n                     # Source Code Link\r\n                     div(\r\n                       style = \"\r\n          background: #f8f9fa;\r\n          padding: 20px;\r\n          border-radius: 8px;\r\n          border: 1px solid #e0e0e0;\r\n        \",\r\n                       h4(style = \"color: #007BFF; margin-top: 0;\", \"üíª Source Code\"),\r\n                       p(style = \"line-height: 1.6;\",\r\n                         \"View and contribute to the code on \",\r\n                         a(href = \"https://github.com/stevensherrin\",\r\n                           target = \"_blank\",\r\n                           \"GitHub\", \r\n                           style = \"color: #007BFF; text-decoration: none;\"),\r\n                         \". Open source for non-commercial use.\"\r\n                       )\r\n                     )\r\n                   ),\r\n                   \r\n                   # Credits Footer\r\n                   div(\r\n                     style = \"\r\n        background: #f8f9fa;\r\n        padding: 20px;\r\n        border-radius: 8px;\r\n        text-align: center;\r\n        color: #666;\r\n      \",\r\n                     p(style = \"margin: 0;\",\r\n                       \"Developed by \",\r\n                       a(href = \"https://www.linkedin.com/in/steven-sherrin\",\r\n                         target = \"_blank\",\r\n                         \"Steven Sherrin\", \r\n                         style = \"color: #007BFF; text-decoration: none;\"),\r\n                       \" (Wentworth Institute of Technology)\"\r\n                     )\r\n                   )\r\n                 )\r\n        )\r\n      )\r\n    )\r\n  ),\r\n  div(class = \"footer\",\r\n      HTML(\"<p>This dashboard was created by <a href='https://www.linkedin.com/in/steven-sherrin' target='_blank'>Steven Sherrin<\/a>. Research was conducted by <a href='https://www.linkedin.com/in/ingerbergom' target='_blank'>Inger Bergom<\/a> (Harvard University) and <a href='https://www.linkedin.com/in/steven-sherrin' target='_blank'>Steven Sherrin<\/a> (Wentworth Institute of Technology).<\/p>\")\r\n  )\r\n)","type":"text"},{"name":"LICENSE","content":"GNU GENERAL PUBLIC LICENSE\r\n                       Version 2, June 1991\r\n\r\n Copyright (C) 1989, 1991 Free Software Foundation, Inc.,\r\n 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\r\n Everyone is permitted to copy and distribute verbatim copies\r\n of this license document, but changing it is not allowed.\r\n\r\n                            Preamble\r\n\r\n  The licenses for most software are designed to take away your\r\nfreedom to share and change it.  By contrast, the GNU General Public\r\nLicense is intended to guarantee your freedom to share and change free\r\nsoftware--to make sure the software is free for all its users.  This\r\nGeneral Public License applies to most of the Free Software\r\nFoundation's software and to any other program whose authors commit to\r\nusing it.  (Some other Free Software Foundation software is covered by\r\nthe GNU Lesser General Public License instead.)  You can apply it to\r\nyour programs, too.\r\n\r\n  When we speak of free software, we are referring to freedom, not\r\nprice.  Our General Public Licenses are designed to make sure that you\r\nhave the freedom to distribute copies of free software (and charge for\r\nthis service if you wish), that you receive source code or can get it\r\nif you want it, that you can change the software or use pieces of it\r\nin new free programs; and that you know you can do these things.\r\n\r\n  To protect your rights, we need to make restrictions that forbid\r\nanyone to deny you these rights or to ask you to surrender the rights.\r\nThese restrictions translate to certain responsibilities for you if you\r\ndistribute copies of the software, or if you modify it.\r\n\r\n  For example, if you distribute copies of such a program, whether\r\ngratis or for a fee, you must give the recipients all the rights that\r\nyou have.  You must make sure that they, too, receive or can get the\r\nsource code.  And you must show them these terms so they know their\r\nrights.\r\n\r\n  We protect your rights with two steps: (1) copyright the software, and\r\n(2) offer you this license which gives you legal permission to copy,\r\ndistribute and/or modify the software.\r\n\r\n  Also, for each author's protection and ours, we want to make certain\r\nthat everyone understands that there is no warranty for this free\r\nsoftware.  If the software is modified by someone else and passed on, we\r\nwant its recipients to know that what they have is not the original, so\r\nthat any problems introduced by others will not reflect on the original\r\nauthors' reputations.\r\n\r\n  Finally, any free program is threatened constantly by software\r\npatents.  We wish to avoid the danger that redistributors of a free\r\nprogram will individually obtain patent licenses, in effect making the\r\nprogram proprietary.  To prevent this, we have made it clear that any\r\npatent must be licensed for everyone's free use or not licensed at all.\r\n\r\n  The precise terms and conditions for copying, distribution and\r\nmodification follow.\r\n\r\n                    GNU GENERAL PUBLIC LICENSE\r\n   TERMS AND CONDITIONS FOR COPYING, DISTRIBUTION AND MODIFICATION\r\n\r\n  0. This License applies to any program or other work which contains\r\na notice placed by the copyright holder saying it may be distributed\r\nunder the terms of this General Public License.  The \"Program\", below,\r\nrefers to any such program or work, and a \"work based on the Program\"\r\nmeans either the Program or any derivative work under copyright law:\r\nthat is to say, a work containing the Program or a portion of it,\r\neither verbatim or with modifications and/or translated into another\r\nlanguage.  (Hereinafter, translation is included without limitation in\r\nthe term \"modification\".)  Each licensee is addressed as \"you\".\r\n\r\nActivities other than copying, distribution and modification are not\r\ncovered by this License; they are outside its scope.  The act of\r\nrunning the Program is not restricted, and the output from the Program\r\nis covered only if its contents constitute a work based on the\r\nProgram (independent of having been made by running the Program).\r\nWhether that is true depends on what the Program does.\r\n\r\n  1. You may copy and distribute verbatim copies of the Program's\r\nsource code as you receive it, in any medium, provided that you\r\nconspicuously and appropriately publish on each copy an appropriate\r\ncopyright notice and disclaimer of warranty; keep intact all the\r\nnotices that refer to this License and to the absence of any warranty;\r\nand give any other recipients of the Program a copy of this License\r\nalong with the Program.\r\n\r\nYou may charge a fee for the physical act of transferring a copy, and\r\nyou may at your option offer warranty protection in exchange for a fee.\r\n\r\n  2. You may modify your copy or copies of the Program or any portion\r\nof it, thus forming a work based on the Program, and copy and\r\ndistribute such modifications or work under the terms of Section 1\r\nabove, provided that you also meet all of these conditions:\r\n\r\n    a) You must cause the modified files to carry prominent notices\r\n    stating that you changed the files and the date of any change.\r\n\r\n    b) You must cause any work that you distribute or publish, that in\r\n    whole or in part contains or is derived from the Program or any\r\n    part thereof, to be licensed as a whole at no charge to all third\r\n    parties under the terms of this License.\r\n\r\n    c) If the modified program normally reads commands interactively\r\n    when run, you must cause it, when started running for such\r\n    interactive use in the most ordinary way, to print or display an\r\n    announcement including an appropriate copyright notice and a\r\n    notice that there is no warranty (or else, saying that you provide\r\n    a warranty) and that users may redistribute the program under\r\n    these conditions, and telling the user how to view a copy of this\r\n    License.  (Exception: if the Program itself is interactive but\r\n    does not normally print such an announcement, your work based on\r\n    the Program is not required to print an announcement.)\r\n\r\nThese requirements apply to the modified work as a whole.  If\r\nidentifiable sections of that work are not derived from the Program,\r\nand can be reasonably considered independent and separate works in\r\nthemselves, then this License, and its terms, do not apply to those\r\nsections when you distribute them as separate works.  But when you\r\ndistribute the same sections as part of a whole which is a work based\r\non the Program, the distribution of the whole must be on the terms of\r\nthis License, whose permissions for other licensees extend to the\r\nentire whole, and thus to each and every part regardless of who wrote it.\r\n\r\nThus, it is not the intent of this section to claim rights or contest\r\nyour rights to work written entirely by you; rather, the intent is to\r\nexercise the right to control the distribution of derivative or\r\ncollective works based on the Program.\r\n\r\nIn addition, mere aggregation of another work not based on the Program\r\nwith the Program (or with a work based on the Program) on a volume of\r\na storage or distribution medium does not bring the other work under\r\nthe scope of this License.\r\n\r\n  3. You may copy and distribute the Program (or a work based on it,\r\nunder Section 2) in object code or executable form under the terms of\r\nSections 1 and 2 above provided that you also do one of the following:\r\n\r\n    a) Accompany it with the complete corresponding machine-readable\r\n    source code, which must be distributed under the terms of Sections\r\n    1 and 2 above on a medium customarily used for software interchange; or,\r\n\r\n    b) Accompany it with a written offer, valid for at least three\r\n    years, to give any third party, for a charge no more than your\r\n    cost of physically performing source distribution, a complete\r\n    machine-readable copy of the corresponding source code, to be\r\n    distributed under the terms of Sections 1 and 2 above on a medium\r\n    customarily used for software interchange; or,\r\n\r\n    c) Accompany it with the information you received as to the offer\r\n    to distribute corresponding source code.  (This alternative is\r\n    allowed only for noncommercial distribution and only if you\r\n    received the program in object code or executable form with such\r\n    an offer, in accord with Subsection b above.)\r\n\r\nThe source code for a work means the preferred form of the work for\r\nmaking modifications to it.  For an executable work, complete source\r\ncode means all the source code for all modules it contains, plus any\r\nassociated interface definition files, plus the scripts used to\r\ncontrol compilation and installation of the executable.  However, as a\r\nspecial exception, the source code distributed need not include\r\nanything that is normally distributed (in either source or binary\r\nform) with the major components (compiler, kernel, and so on) of the\r\noperating system on which the executable runs, unless that component\r\nitself accompanies the executable.\r\n\r\nIf distribution of executable or object code is made by offering\r\naccess to copy from a designated place, then offering equivalent\r\naccess to copy the source code from the same place counts as\r\ndistribution of the source code, even though third parties are not\r\ncompelled to copy the source along with the object code.\r\n\r\n  4. You may not copy, modify, sublicense, or distribute the Program\r\nexcept as expressly provided under this License.  Any attempt\r\notherwise to copy, modify, sublicense or distribute the Program is\r\nvoid, and will automatically terminate your rights under this License.\r\nHowever, parties who have received copies, or rights, from you under\r\nthis License will not have their licenses terminated so long as such\r\nparties remain in full compliance.\r\n\r\n  5. You are not required to accept this License, since you have not\r\nsigned it.  However, nothing else grants you permission to modify or\r\ndistribute the Program or its derivative works.  These actions are\r\nprohibited by law if you do not accept this License.  Therefore, by\r\nmodifying or distributing the Program (or any work based on the\r\nProgram), you indicate your acceptance of this License to do so, and\r\nall its terms and conditions for copying, distributing or modifying\r\nthe Program or works based on it.\r\n\r\n  6. Each time you redistribute the Program (or any work based on the\r\nProgram), the recipient automatically receives a license from the\r\noriginal licensor to copy, distribute or modify the Program subject to\r\nthese terms and conditions.  You may not impose any further\r\nrestrictions on the recipients' exercise of the rights granted herein.\r\nYou are not responsible for enforcing compliance by third parties to\r\nthis License.\r\n\r\n  7. If, as a consequence of a court judgment or allegation of patent\r\ninfringement or for any other reason (not limited to patent issues),\r\nconditions are imposed on you (whether by court order, agreement or\r\notherwise) that contradict the conditions of this License, they do not\r\nexcuse you from the conditions of this License.  If you cannot\r\ndistribute so as to satisfy simultaneously your obligations under this\r\nLicense and any other pertinent obligations, then as a consequence you\r\nmay not distribute the Program at all.  For example, if a patent\r\nlicense would not permit royalty-free redistribution of the Program by\r\nall those who receive copies directly or indirectly through you, then\r\nthe only way you could satisfy both it and this License would be to\r\nrefrain entirely from distribution of the Program.\r\n\r\nIf any portion of this section is held invalid or unenforceable under\r\nany particular circumstance, the balance of the section is intended to\r\napply and the section as a whole is intended to apply in other\r\ncircumstances.\r\n\r\nIt is not the purpose of this section to induce you to infringe any\r\npatents or other property right claims or to contest validity of any\r\nsuch claims; this section has the sole purpose of protecting the\r\nintegrity of the free software distribution system, which is\r\nimplemented by public license practices.  Many people have made\r\ngenerous contributions to the wide range of software distributed\r\nthrough that system in reliance on consistent application of that\r\nsystem; it is up to the author/donor to decide if he or she is willing\r\nto distribute software through any other system and a licensee cannot\r\nimpose that choice.\r\n\r\nThis section is intended to make thoroughly clear what is believed to\r\nbe a consequence of the rest of this License.\r\n\r\n  8. If the distribution and/or use of the Program is restricted in\r\ncertain countries either by patents or by copyrighted interfaces, the\r\noriginal copyright holder who places the Program under this License\r\nmay add an explicit geographical distribution limitation excluding\r\nthose countries, so that distribution is permitted only in or among\r\ncountries not thus excluded.  In such case, this License incorporates\r\nthe limitation as if written in the body of this License.\r\n\r\n  9. The Free Software Foundation may publish revised and/or new versions\r\nof the General Public License from time to time.  Such new versions will\r\nbe similar in spirit to the present version, but may differ in detail to\r\naddress new problems or concerns.\r\n\r\nEach version is given a distinguishing version number.  If the Program\r\nspecifies a version number of this License which applies to it and \"any\r\nlater version\", you have the option of following the terms and conditions\r\neither of that version or of any later version published by the Free\r\nSoftware Foundation.  If the Program does not specify a version number of\r\nthis License, you may choose any version ever published by the Free Software\r\nFoundation.\r\n\r\n  10. If you wish to incorporate parts of the Program into other free\r\nprograms whose distribution conditions are different, write to the author\r\nto ask for permission.  For software which is copyrighted by the Free\r\nSoftware Foundation, write to the Free Software Foundation; we sometimes\r\nmake exceptions for this.  Our decision will be guided by the two goals\r\nof preserving the free status of all derivatives of our free software and\r\nof promoting the sharing and reuse of software generally.\r\n\r\n                            NO WARRANTY\r\n\r\n  11. BECAUSE THE PROGRAM IS LICENSED FREE OF CHARGE, THERE IS NO WARRANTY\r\nFOR THE PROGRAM, TO THE EXTENT PERMITTED BY APPLICABLE LAW.  EXCEPT WHEN\r\nOTHERWISE STATED IN WRITING THE COPYRIGHT HOLDERS AND/OR OTHER PARTIES\r\nPROVIDE THE PROGRAM \"AS IS\" WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED\r\nOR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF\r\nMERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE.  THE ENTIRE RISK AS\r\nTO THE QUALITY AND PERFORMANCE OF THE PROGRAM IS WITH YOU.  SHOULD THE\r\nPROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF ALL NECESSARY SERVICING,\r\nREPAIR OR CORRECTION.\r\n\r\n  12. IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING\r\nWILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MAY MODIFY AND/OR\r\nREDISTRIBUTE THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES,\r\nINCLUDING ANY GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING\r\nOUT OF THE USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED\r\nTO LOSS OF DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY\r\nYOU OR THIRD PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER\r\nPROGRAMS), EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE\r\nPOSSIBILITY OF SUCH DAMAGES.\r\n\r\n                     END OF TERMS AND CONDITIONS\r\n\r\n            How to Apply These Terms to Your New Programs\r\n\r\n  If you develop a new program, and you want it to be of the greatest\r\npossible use to the public, the best way to achieve this is to make it\r\nfree software which everyone can redistribute and change under these terms.\r\n\r\n  To do so, attach the following notices to the program.  It is safest\r\nto attach them to the start of each source file to most effectively\r\nconvey the exclusion of warranty; and each file should have at least\r\nthe \"copyright\" line and a pointer to where the full notice is found.\r\n\r\n    <one line to give the program's name and a brief idea of what it does.>\r\n    Copyright (C) <year>  <name of author>\r\n\r\n    This program is free software; you can redistribute it and/or modify\r\n    it under the terms of the GNU General Public License as published by\r\n    the Free Software Foundation; either version 2 of the License, or\r\n    (at your option) any later version.\r\n\r\n    This program is distributed in the hope that it will be useful,\r\n    but WITHOUT ANY WARRANTY; without even the implied warranty of\r\n    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\r\n    GNU General Public License for more details.\r\n\r\n    You should have received a copy of the GNU General Public License along\r\n    with this program; if not, write to the Free Software Foundation, Inc.,\r\n    51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA.\r\n\r\nAlso add information on how to contact you by electronic and paper mail.\r\n\r\nIf the program is interactive, make it output a short notice like this\r\nwhen it starts in an interactive mode:\r\n\r\n    Gnomovision version 69, Copyright (C) year name of author\r\n    Gnomovision comes with ABSOLUTELY NO WARRANTY; for details type `show w'.\r\n    This is free software, and you are welcome to redistribute it\r\n    under certain conditions; type `show c' for details.\r\n\r\nThe hypothetical commands `show w' and `show c' should show the appropriate\r\nparts of the General Public License.  Of course, the commands you use may\r\nbe called something other than `show w' and `show c'; they could even be\r\nmouse-clicks or menu items--whatever suits your program.\r\n\r\nYou should also get your employer (if you work as a programmer) or your\r\nschool, if any, to sign a \"copyright disclaimer\" for the program, if\r\nnecessary.  Here is a sample; alter the names:\r\n\r\n  Yoyodyne, Inc., hereby disclaims all copyright interest in the program\r\n  `Gnomovision' (which makes passes at compilers) written by James Hacker.\r\n\r\n  <signature of Ty Coon>, 1 April 1989\r\n  Ty Coon, President of Vice\r\n\r\nThis General Public License does not permit incorporating your program into\r\nproprietary programs.  If your program is a subroutine library, you may\r\nconsider it more useful to permit linking proprietary applications with the\r\nlibrary.  If this is what you want to do, use the GNU Lesser General\r\nPublic License instead of this License.\n","type":"text"},{"name":"README.md","content":"# IR-Low-Effort-Survey-Responses-App\n App for detecting low-effort responses for popular IR surveys\n","type":"text"},{"name":"deploy_shinylive.R","content":"library(shinylive)\r\nlibrary(fs)\r\n#sessionInfo()\r\n\r\n# Define the path to your existing Shiny app\r\nexisting_app_path <- \"C:/Users/sherrins/OneDrive - Wentworth Institute of Technology/Documents/GitHub/IR-Low-Effort-Survey-Responses-App\"\r\n\r\nshinylive::export(appdir = existing_app_path, destdir = \"C:/Users/sherrins/OneDrive - Wentworth Institute of Technology/Documents/GitHub/IR-Low-Effort-Survey-Responses-App/docs\")\r\n\r\n#httpuv::runStaticServer(\"docs\")\r\n\r\nhttpuv::runStaticServer(\"C:/Users/sherrins/OneDrive - Wentworth Institute of Technology/Documents/GitHub/IR-Low-Effort-Survey-Responses-App/docs\")\r\n\r\n#httpuv::runStaticServer(\"docs/\", port=8008)\r\n\r\n\r\n","type":"text"},{"name":"functions.R","content":"# Mahad function (from careless package)\r\nmahad <- function(x, plot = TRUE, flag = FALSE, confidence = 0.99, na.rm = TRUE) {\r\n  if(na.rm == FALSE) {\r\n    if(any(is.na(x)) == TRUE) {stop(\"Some values are NA. Mahalanobis distance was not computed.\r\n                                      Use na.rm = TRUE to use available cases.\", call. = FALSE)}\r\n  }\r\n  \r\n  #Subfunction \"mahad\" (from psych package)\r\n  outlier <- \r\n    function(x,plot=TRUE,bad=5,na.rm=TRUE,xlab,ylab,...) {\r\n      if(missing(xlab)) xlab <- expression(\"Quantiles of \" * ~chi ^2)\r\n      if(missing(ylab)) ylab <- expression(\"Mahalanobis \" * D^2)\r\n      rn <- rownames(x)\r\n      nvar <- ncol(x)\r\n      n.obs <- nrow(x)\r\n      if(!is.matrix(x)) x <- as.matrix(x)\r\n      nvar <- ncol(x)\r\n      Sx <- cov(x,use=\"pairwise\")\r\n      Sx.inv <- solve(Sx)\r\n      # Mx <- colMeans(x,na.rm=na.rm)\r\n      # x <- sweep(x,2,Mx)\r\n      #x <- t(scale(t(x),scale=FALSE))\r\n      x <- scale(x,scale=FALSE)\r\n      D2 <- t(apply(x,1,function(xx) colSums(xx * Sx.inv,na.rm=TRUE)))\r\n      D2 <- rowSums(D2*x,na.rm=TRUE)\r\n      names(D2) <- rn\r\n      \r\n      if(plot) {\r\n        Chi2 <- qchisq(ppoints(n.obs), df =  nvar)\r\n        qqplot(Chi2, D2,\r\n               main = expression(\"Q-Q plot of Mahalanobis\" * ~D^2 *\r\n                                   \" vs. quantiles of\" * ~ chi[nvar]^2),xlab=xlab,ylab=ylab,...)\r\n        abline(0, 1, col = 'gray')\r\n        worst <- order(D2,decreasing=TRUE)\r\n        text(Chi2[n.obs:(n.obs-bad+1)],D2[worst[1:bad]],names(D2)[worst[1:bad]],pos=3,...)\r\n      }\r\n      return(D2)\r\n    }\r\n  \r\n  #remove rows with all NA and issue warning\r\n  complete.na <- apply(x, 1, function(y) { all(is.na(y)) } )\r\n  if(any(complete.na)) {\r\n    warning(\"Some cases contain only NA values. The Mahalanobis distance will be calculated using available cases.\",\r\n            call. = FALSE) }\r\n  x_filtered <- x[!complete.na,]\r\n  \r\n  maha_data <- as.numeric(outlier(x_filtered, plot, bad = 0, na.rm = na.rm))\r\n  d_sq <- rep_len(NA, nrow(x_filtered))\r\n  d_sq[!complete.na] <- maha_data\r\n  \r\n  if(flag == TRUE) {\r\n    cut <- stats::qchisq(confidence, ncol(x))\r\n    flagged <- (d_sq > cut)\r\n    return(data.frame(d_sq = d_sq, flagged = flagged))\r\n  }\r\n  else{ return(d_sq) }\r\n}\r\n\r\n# IRV function (from careless package)\r\nirv <- function(x, na.rm = TRUE, split = FALSE, num.split = 3) {\r\n  out <- apply(x, 1, stats::sd, na.rm = na.rm)\r\n  \r\n  if(split == TRUE) {\r\n    chunk <- function(x,n) split(x, cut(seq_along(x), n, labels = FALSE))\r\n    split_x <- apply(x, 1, chunk, num.split)\r\n    out_split <- t(replicate(nrow(x), rep(NA, num.split)))\r\n    colnames(out_split) <- paste0(\"irv\",1:num.split)\r\n    for(k in 1:nrow(out_split)) {\r\n      split_x_single <- split_x[[k]]\r\n      out_split[k,] <- unlist(lapply(split_x_single, stats::sd, na.rm = na.rm), use.names = FALSE)\r\n    }\r\n    out_split <- data.frame(out, out_split)\r\n    colnames(out_split)[1] <- \"irvTotal\"\r\n    return(out_split)} else { #split subsection end\r\n      return(out)\r\n    }\r\n}\r\n\r\n# Longstring function (from careless package)\r\nlongstring <- function(x, avg=FALSE) {\r\n  \r\n  # subfunction that calculates the length of consecutive identical responses\r\n  rle_string <- function(x) {\r\n    rle_list <- rle(x)\r\n    longstr <- max(rle_list$lengths)\r\n    avgstr <- mean(rle_list$lengths)\r\n    return(cbind(longstr, avgstr))\r\n  }\r\n  \r\n  # apply the subfunctions to each row (case, subject)\r\n  output <- apply(x, 1, rle_string)\r\n  output <- data.frame(t(output))\r\n  colnames(output) <- (c('longstr','avgstr'))\r\n  \r\n  if(avg == TRUE) {\r\n    return(output)\r\n  } else {\r\n    return(output[,'longstr'])\r\n  }\r\n}\r\n\r\n#Longstring number of times 7 or more consecutive identical responses (modified from longstring in careless package)\r\nlongstring_n_times <- function(x, avg=FALSE, threshold=6) {\r\n  \r\n  # subfunction that calculates the length of consecutive identical responses\r\n  rle_string <- function(x) {\r\n    rle_list <- rle(x)\r\n    longstr <- max(rle_list$lengths)\r\n    avgstr <- mean(rle_list$lengths)\r\n    count_longstr <- sum(rle_list$lengths > threshold)\r\n    return(cbind(longstr, avgstr, count_longstr))\r\n  }\r\n  \r\n  # apply the subfunctions to each row (case, subject)\r\n  output <- apply(x, 1, rle_string)\r\n  output <- data.frame(t(output))\r\n  colnames(output) <- c('longstr','avgstr', 'count_longstr')\r\n  \r\n  if(avg == TRUE) {\r\n    return(output)\r\n  } else {\r\n    return(output[, c('longstr', 'count_longstr')])\r\n  }\r\n}\r\n\r\n# Psych synonyms function (from careless package)\r\npsychsyn <- function(x, critval=.60, anto=FALSE, diag=FALSE, resample_na=TRUE) {\r\n  x <- as.matrix(x)\r\n  item_pairs <- get_item_pairs(x, critval, anto)\r\n  \r\n  synonyms <- apply(x,1,syn_for_one, item_pairs, resample_na)\r\n  synonyms_df <- as.data.frame(aperm(synonyms))\r\n  colnames(synonyms_df) <- c(\"numPairs\", \"cor\")\r\n  \r\n  if(diag==TRUE) { return(synonyms_df) }\r\n  else { return(synonyms_df$cor) }\r\n}\r\n\r\n# Helper function that identifies psychometric synonyms in a given dataset\r\nget_item_pairs <- function(x, critval=.60, anto=FALSE) {\r\n  critval <- abs(critval) #Dummy Proofing\r\n  \r\n  correlations <- stats::cor(x, use = \"pairwise.complete.obs\")\r\n  correlations[upper.tri(correlations, diag=TRUE)] <- NA\r\n  correlations <- as.data.frame(as.table(correlations))\r\n  \r\n  # Identifying item pairs differs depending on whether the user wants\r\n  # Psychometric Synonyms or Psychometric Antonyms\r\n  if(anto==FALSE) {\r\n    item_pair_names <- correlations[which(correlations$Freq > critval, arr.ind=TRUE),c(1,2)]\r\n    if(nrow(item_pair_names)==0) {\r\n      stop(\"No Psychometric Synonyms found.\")\r\n    }\r\n  }\r\n  else if(anto==TRUE) {\r\n    item_pair_names <- correlations[which(correlations$Freq < -critval, arr.ind=TRUE),c(1,2)]\r\n    if(nrow(item_pair_names)==0) {\r\n      stop(\"No Psychometric Antonyms found.\")\r\n    }\r\n  }\r\n  \r\n  matches <- item_pair_names\r\n  return(matches)\r\n}\r\n\r\n# Helper function to calculate the within person correlation for a single individual\r\nsyn_for_one <- function(x, item_pairs, resample_na) {\r\n  item_pairs_omit_na <- which(!(is.na(x[item_pairs[,1]]) | is.na(x[item_pairs[,2]])))\r\n  sum_item_pairs <- length(item_pairs_omit_na)\r\n  #only execute if more than two item pairs\r\n  if(sum_item_pairs > 2) {\r\n    itemvalues <- cbind(as.numeric(x[as.numeric(item_pairs[,1])]), as.numeric(x[as.numeric(item_pairs[,2])]))\r\n    \r\n    # helper that calculates within-person correlation\r\n    psychsyn_cor <- function(x) {\r\n      suppressWarnings(stats::cor(x, use = \"pairwise.complete.obs\", method = \"pearson\")[1,2])\r\n    }\r\n    \r\n    # if resample_na == TRUE, re-calculate psychsyn should a result return NA\r\n    if(resample_na == TRUE) {\r\n      counter <- 1\r\n      synvalue <- psychsyn_cor(itemvalues)\r\n      while(counter <= 10 & is.na(synvalue)) {\r\n        itemvalues <- t(apply(itemvalues, 1, sample, 2, replace = F))\r\n        synvalue <- psychsyn_cor(itemvalues)\r\n        counter = counter+1\r\n      }\r\n    } else {\r\n      synvalue <- psychsyn_cor(itemvalues) # executes if resample_na == FALSE\r\n    }\r\n    \r\n  } else {synvalue <- NA} # executes if insufficient item pairs\r\n  \r\n  return(c(sum_item_pairs, synvalue))\r\n}\r\n\r\n# Function to remove singular columns (i.e. columns with zero variance or perfect collinearity)\r\n# Some raw data files, such as for NSSE, sometimes have identical columns\r\nremove_singular_columns <- function(data, threshold = 0.999) {\r\n  # Store original row count\r\n  original_rows <- nrow(data)\r\n  \r\n  # Convert all columns to numeric\r\n  data_numeric <- data %>%\r\n    mutate(across(everything(), as.numeric))\r\n  \r\n  # Remove columns with zero variance, but keep all rows\r\n  var_zero <- apply(data_numeric, 2, var, na.rm = TRUE) == 0\r\n  if(any(var_zero)) {\r\n    data_numeric <- data_numeric[, !var_zero]\r\n    cat(\"Removed\", sum(var_zero), \"columns with zero variance\\n\")\r\n  }\r\n  \r\n  # Calculate correlation matrix with pairwise complete obs\r\n  cor_matrix <- cor(data_numeric, use = \"pairwise.complete.obs\")\r\n  \r\n  # Find highly correlated pairs\r\n  high_cor <- which(abs(cor_matrix) > threshold & cor_matrix != 1, arr.ind = TRUE)\r\n  \r\n  if(nrow(high_cor) > 0) {\r\n    cols_to_remove <- c()\r\n    \r\n    for(i in 1:nrow(high_cor)) {\r\n      if(high_cor[i,1] < high_cor[i,2]) {\r\n        col1 <- colnames(data_numeric)[high_cor[i,1]]\r\n        col2 <- colnames(data_numeric)[high_cor[i,2]]\r\n        \r\n        if(!(col1 %in% cols_to_remove) && !(col2 %in% cols_to_remove)) {\r\n          na_count1 <- sum(is.na(data_numeric[[col1]]))\r\n          na_count2 <- sum(is.na(data_numeric[[col2]]))\r\n          \r\n          if(na_count1 >= na_count2) {\r\n            cols_to_remove <- c(cols_to_remove, col1)\r\n          } else {\r\n            cols_to_remove <- c(cols_to_remove, col2)\r\n          }\r\n        }\r\n      }\r\n    }\r\n    \r\n    if(length(cols_to_remove) > 0) {\r\n      cat(\"Removed\", length(cols_to_remove), \"highly correlated columns:\", \r\n          paste(cols_to_remove, collapse = \", \"), \"\\n\")\r\n      data_numeric <- data_numeric %>% select(-all_of(cols_to_remove))\r\n    }\r\n  }\r\n  \r\n  # Verify no rows were lost\r\n  if(nrow(data_numeric) != original_rows) {\r\n    warning(\"Row count changed during processing. This should not happen.\")\r\n  }\r\n  \r\n  return(data_numeric)\r\n}\r\n\r\n# Function to check required variables\r\ncheck_missing_vars <- function(df) {\r\n  df_columns <- colnames(df)\r\n  missing_vars <- setdiff(required_vars, df_columns)\r\n  \r\n  if (length(missing_vars) > 0) {\r\n    print(paste(\"The following columns are missing from your raw file:\", \r\n                paste(missing_vars, collapse = \", \"), \r\n                \". Some of this may be due to analyzing a particular year for the survey, especially older years. Keep in mind this may prevent the analysis from running properly.\"))\r\n  } else {\r\n    print(\"All required columns are present.\")\r\n  }\r\n  \r\n  return(missing_vars)\r\n}\r\n\r\n# Function to clean and prep the dataframe (e.g. remove NA columns)\r\nclean_data <- function(df) {\r\n  df <- clean_names(df)\r\n  print(\"Column names successfully cleaned\")\r\n  \r\n  na_or_empty_names <- which(is.na(names(df)) | names(df) == \"\")\r\n  \r\n  if (length(na_or_empty_names) > 0) {\r\n    cat(\"Columns with NA or empty names:\", na_or_empty_names, \"\\n\")\r\n    names(df)[na_or_empty_names] <- paste(\"V\", na_or_empty_names, sep = \"\")\r\n  } else {\r\n    print(\"No columns with NA or empty names\")\r\n  }\r\n  \r\n  df <- df %>% mutate(unique_id = paste0(row_number()))\r\n  print(\"Unique identifier for each row created\")\r\n  \r\n  assign(\"df\", df, envir = .GlobalEnv)\r\n  return(df)\r\n}\r\n\r\n# Function to process a single filter/analysis step\r\nprocess_step <- function(df, step_number, condition_fn, flag_threshold, step_desc) {\r\n  result <- list()\r\n  result$flagged <- condition_fn(df)\r\n  result$flag_count <- sum(result$flagged, na.rm = TRUE)\r\n  result$remaining_ids <- df$unique_id[!result$flagged]\r\n  result$step_desc <- step_desc\r\n  return(result)\r\n}\r\n\r\n# Function to calculate mahalanobis distance in app\r\ncalculate_mahalanobis <- function(df) {\r\n  tryCatch({\r\n    df_filtered <- remove_singular_columns(select(df, -unique_id))\r\n    mahad_dist <- scale(mahad(df_filtered))\r\n    return(mahad_dist)\r\n  }, error = function(e) {\r\n    warning(\"Error in Mahalanobis distance calculation: \", e$message)\r\n    return(rep(NA, nrow(df)))\r\n  })\r\n}\r\n\r\n# Function to process psychometric synonyms in app\r\ncalculate_psychsyn <- function(df) {\r\n  tryCatch({\r\n    df_filtered <- remove_singular_columns(select(df, -unique_id))\r\n    syn_values <- psychsyn(df_filtered, critval = .50)\r\n    return(syn_values)\r\n  }, error = function(e) {\r\n    warning(\"Error in psychometric synonym calculation: \", e$message)\r\n    return(rep(NA, nrow(df)))\r\n  })\r\n}\r\n\r\n# Function to calculate repeated patterns in app\r\ncalculate_repeated_pattern_percentage <- function(data, lag) {\r\n  # Handle non-numeric columns\r\n  data_numeric <- data %>%\r\n    select_if(function(x) is.numeric(x) | all(grepl(\"^[0-9]+$\", na.omit(x))))\r\n  \r\n  # Convert remaining character columns to numeric if possible\r\n  data_numeric <- data_numeric %>%\r\n    mutate(across(everything(), as.numeric))\r\n  \r\n  # Calculate the number of matches with lagged values\r\n  matches <- rowSums(data_numeric == lag(data_numeric, n = lag, default = NA), na.rm = TRUE)\r\n  \r\n  # Calculate total non-NA values\r\n  total_values <- rowSums(!is.na(data_numeric))\r\n  \r\n  # Calculate percentage\r\n  percentage <- (matches / total_values) * 100\r\n  \r\n  return(percentage)\r\n}\r\n\r\n# Function to calculate longstring in app\r\ncalculate_longstring_ratio <- function(df, set_name, set_columns) {\r\n  # Check if all columns exist in the dataframe\r\n  existing_columns <- intersect(set_columns, colnames(df))\r\n  \r\n  if (length(existing_columns) > 0) {\r\n    # Calculate longstring only for existing columns\r\n    df[[paste0(set_name, \"_longstring\")]] <- as.numeric(\r\n      longstring(df[, existing_columns, drop = FALSE]) / \r\n        rowSums(!is.na(df[, existing_columns, drop = FALSE]))\r\n    )\r\n  } else {\r\n    # If no columns exist, set ratio to 0\r\n    df[[paste0(set_name, \"_longstring\")]] <- 0\r\n  }\r\n  \r\n  return(df)\r\n}","type":"text"},{"name":"nsse.R","content":"# Load necessary libraries\r\nlibrary(openxlsx)\r\nlibrary(writexl)\r\nlibrary(dplyr)\r\nlibrary(tidyr)\r\nlibrary(ggplot2)\r\nlibrary(purrr)\r\nlibrary(janitor)\r\nlibrary(gtools)\r\nlibrary(conflicted)\r\nlibrary(reactable)\r\nlibrary(scales)\r\nlibrary(crosstalk)\r\nlibrary(htmltools)\r\n\r\nconflicts_prefer(base::as.numeric())\r\nconflicts_prefer(base::is.character())\r\nconflicts_prefer(base::`&&`)\r\nconflicts_prefer(base::`||`)\r\nconflicts_prefer(dplyr::filter)\r\nconflicts_prefer(dplyr::lag)\r\n\r\n# Parameters\r\ndone <- 0\r\n\r\n# Parameter: Filter 1\r\nDURATION_THRESHOLD_MIN <- 3  # Minimum duration threshold in minutes\r\n\r\n# Parameter: Filter 2\r\nMISSING_THRESHOLD_PCT <- 50  # Maximum percentage of missing values allowed\r\n\r\n# Parameter: Filter 3\r\nLONGSTRING_THRESHOLD <- 15   # Maximum number of identical consecutive responses\r\n\r\n# Parameter: Filter 4\r\nREPEATED_LONGSTRING_THRESHOLD <- 6 # Number of consecutive identical responses to count as a longstring\r\nREPEATED_LONGSTRING_COUNT <- 3  # Number of longstrings required to flag a response\r\n\r\n# Parameter: Filter 5\r\nSCALE_STRAIGHTLINE_THRESHOLD <- 4   # Number of scales that need to be straightlined to flag a response\r\n\r\n# Parameter: Filter 6\r\nPATTERN_PERCENTAGE_THRESHOLD <- 60  # Percentage threshold for repetitive patterns\r\nPATTERN_LENGTHS <- c(2, 3, 4, 5) # Lengths of patterns to check for (e.g. AB-AB-AB, ABC-ABC-ABC)\r\n\r\n# Parameter: Filter 7\r\nMAX_WEEKLY_HOURS <- 140    # Maximum realistic total weekly hours for \"how many hours per week\" question set\r\n\r\n# Parameter: Filter 8\r\nMAHALANOBIS_THRESHOLD <- 4.0    # Threshold for Mahalanobis distance\r\nPSYCHSYN_THRESHOLD <- 0.0       # Threshold for psychometric synonyms correlation\r\n\r\n# List of required variables to run analyses\r\n# Users who are missing any of these variables will be given an alert before running the data.\r\nrequired_vars <- c(\r\n  \"askquest\", \"drafts\", \"unprepared\", \"attendart\",\r\n  \"CLaskhelp\", \"CLexplain\", \"CLstudy\", \"CLproject\", \"present\",\r\n  \"RIintegrate\", \"RIsocietal\", \"RIdiverse\", \"RIownview\", \"RIperspect\",\r\n  \"RInewview\", \"RIconnect\", \"SFcareer\", \"SFotherwork\", \"SFdiscuss\",\r\n  \"SFperform\", \"memorize\", \"HOapply\", \"HOanalyze\", \"HOevaluate\",\r\n  \"HOform\", \"ETgoals\", \"ETorganize\", \"ETexample\", \"ETdraftfb\",\r\n  \"ETfeedback\", \"QRconclude\", \"QRproblem\", \"QRevaluate\", \r\n  \"DDrace\", \"DDeconomic\", \"DDreligion\", \"DDpolitical\",\r\n  \"LSreading\", \"LSnotes\", \"LSsummary\",\r\n  \"challenge\", \"intern\", \"leader\", \"learncom\", \"abroad\",\r\n  \"research\", \"capstone\", \"servcourse\",\r\n  \"QIstudent\", \"QIadvisor\", \"QIfaculty\", \"QIstaff\", \"QIadmin\",\r\n  \"empstudy\", \"SEacademic\", \"SElearnsup\", \"SEdiverse\", \"SEsocial\", \"SEwellness\", \"SEnonacad\", \"SEactivities\", \"SEevents\",\r\n  \"pgwrite\", \"pgwspeak\",\"pgthink\", \"pganalyze\", \"pgwork\", \"pgothers\", \"pgvalues\", \"pgdiverse\", \"pgprobsolve\", \"pgcitizen\",\r\n  \"tmprephrs\",\"tmcocurrhrs\", \"tmworkonhrs\", \"tmworkoffhrs\", \"tmservicehrs\",\r\n  \"tmrelaxhrs\", \"tmcarehrs\", \"tmcommutehrs\", \"duration\"\r\n)\r\n\r\n# List of NSSE subscales\r\nquestion_sets <- list(\r\n  q_set_1 = c(\"askquest\", \"c_laskhelp\", \"c_lexplain\", \"c_lstudy\", \"c_lproject\", \"present\"),\r\n  q_set_2 = c(\"r_iintegrate\", \"r_isocietal\", \"r_idiverse\", \"r_iownview\", \"r_iperspect\", \"r_inewview\", \"r_iconnect\"),\r\n  q_set_3 = c(\"memorize\", \"h_oapply\", \"h_oanalyze\", \"h_oevaluate\", \"h_oform\"),\r\n  q_set_4 = c(\"e_tgoals\", \"e_torganize\", \"e_texample\", \"e_tdraftfb\", \"e_tfeedback\", \"e_tcriteria\", \"e_treview\", \"e_tprefer\", \"e_tdemonstrate\"),\r\n  q_set_5 = c(\"d_drace\", \"d_deconomic\", \"d_dreligion\", \"d_dpolitical\", \"d_dsexorient\", \"d_dcountry\"),\r\n  q_set_6 = c(\"intern\", \"leader\", \"learncom\", \"abroad\", \"research\", \"capstone\", \"servcourse\"),\r\n  q_set_7 = c(\"empstudy\", \"s_eacademic\", \"s_elearnsup\", \"s_ediverse\", \"s_esocial\", \"s_ewellness\", \"s_enonacad\", \"s_eactivities\", \"s_eevents\"),\r\n  q_set_8 = c(\"tmprephrs\", \"tmcocurrhrs\", \"tmworkonhrs\", \"tmworkoffhrs\", \"tmservicehrs\", \"tmrelaxhrs\", \"tmcarehrs\", \"tmcommutehrs\")\r\n)\r\n\r\n# Function to remove recoded and estimated variables\r\nremove_recoded_vars <- function(df) {\r\n  recoded_vars <- c(\"unpreparedr\", \"wrshortnum\", \"wrmednum\", \"wrlongnum\", \"wrpages\",\r\n                    \"HIPsumFY\", \"HIPsumSR\", \"QIstudentR\", \"QIadvisorR\", \"QIfacultyR\",\r\n                    \"QIstaffR\", \"QIadminR\", \"tmprep\", \"tmcocurr\", \"tmworkon\", \"tmworkoff\",\r\n                    \"tmworkhrs\", \"tmservice\", \"tmrelax\", \"tmcare\", \"tmcommute\", \"tmread\",\r\n                    \"reading\", \"tmreadinghrscol\", \"wrshort\", \"wrmed\", \"wrlong\",\r\n                    \"wrshortnum\", \"wrmednum\", \"wrlongnum\", \"wrpages\")\r\n  \r\n  df <- df %>% select(-any_of(recoded_vars))\r\n  print(\"Flagged recoded and/or estimated variables not used in analyses.\")\r\n  \r\n  return(df)\r\n}\r\n\r\n# Function to read the uploaded file\r\nread_uploaded_file <- function(file) {\r\n  ext <- tools::file_ext(file$name)\r\n  \r\n  if (ext == \"csv\") {\r\n    df <- read.csv(file$datapath)\r\n  } else if (ext == \"xlsx\") {\r\n    df <- openxlsx::read.xlsx(file$datapath)\r\n  } else if (ext == \"sav\") {\r\n    df <- haven::read_sav(file$datapath)\r\n    df <- as.data.frame(df)\r\n  } else {\r\n    stop(\"Invalid file type. Please upload a .csv, .xlsx, or .sav file.\")\r\n  }\r\n  \r\n  assign(\"df\", df, envir = .GlobalEnv)\r\n  return(df)\r\n}\r\n\r\n# Main function to identify careless responses\r\nidentify_careless_responses <- function(df) {\r\n  # Initialize results storage\r\n  results <- list()\r\n  step_results <- list()\r\n  \r\n  # Create initial dataframe with numeric values\r\n  df_main <- df %>%\r\n    select(unique_id, duration, askquest:s_eevents) %>%\r\n    mutate(across(everything(), ~ as.numeric(as.character(.))))\r\n  \r\n  # Keep track of all flagged IDs across steps\r\n  all_flagged_ids <- character(0)\r\n  \r\n  # Step 1: Duration check\r\n  # First calculate for all responses\r\n  step_1_condition <- df_main$duration <= DURATION_THRESHOLD_MIN  & !is.na(df_main$duration)\r\n  total_step_1_flags <- sum(step_1_condition, na.rm = TRUE)\r\n  \r\n  # Then process for sequential filtering\r\n  step_results[[1]] <- process_step(\r\n    df = df_main,\r\n    step_number = 1,\r\n    condition_fn = function(x) x$duration <= DURATION_THRESHOLD_MIN  & !is.na(x$duration),\r\n    flag_threshold = DURATION_THRESHOLD_MIN,\r\n    step_desc = paste(\"Completed survey in\", DURATION_THRESHOLD_MIN, \"minutes or less\")\r\n  )\r\n  all_flagged_ids <- union(all_flagged_ids, \r\n                           df_main$unique_id[step_results[[1]]$flagged])\r\n  \r\n  # Step 2: Missing values check\r\n  # First calculate for all responses\r\n  df_for_missing <- select(df_main, -unique_id, -duration)\r\n  step_2_condition <- rowSums(is.na(df_for_missing)) / ncol(df_for_missing) * 100 > MISSING_THRESHOLD_PCT\r\n  total_step_2_flags <- sum(step_2_condition, na.rm = TRUE)\r\n  \r\n  # Then process for sequential filtering\r\n  step_results[[2]] <- process_step(\r\n    df = df_main[!df_main$unique_id %in% all_flagged_ids, ],\r\n    step_number = 2,\r\n    condition_fn = function(x) {\r\n      missing_pct <- rowSums(is.na(select(x, -unique_id, -duration))) / \r\n        ncol(select(x, -unique_id, -duration)) * 100\r\n      missing_pct > MISSING_THRESHOLD_PCT\r\n    },\r\n    flag_threshold = MISSING_THRESHOLD_PCT,\r\n    step_desc = paste(\"More than\", MISSING_THRESHOLD_PCT, \"% of survey questions missing\")\r\n  )\r\n  all_flagged_ids <- union(all_flagged_ids, \r\n                           df_main$unique_id[!df_main$unique_id %in% all_flagged_ids][step_results[[2]]$flagged])\r\n  \r\n  # Step 3: Longstring check\r\n  # First calculate for all responses\r\n  step_3_condition <- longstring(select(df_main, -unique_id, -duration))\r\n  total_step_3_flags <- sum(step_3_condition >= LONGSTRING_THRESHOLD, na.rm = TRUE)\r\n  \r\n  # Then process for sequential filtering\r\n  step_results[[3]] <- process_step(\r\n    df = df_main[!df_main$unique_id %in% all_flagged_ids, ],\r\n    step_number = 3,\r\n    condition_fn = function(x) {\r\n      ls_values <- longstring(select(x, -unique_id, -duration))\r\n      ls_values >= LONGSTRING_THRESHOLD\r\n    },\r\n    flag_threshold = LONGSTRING_THRESHOLD,\r\n    step_desc = paste(\"Straightlined\", LONGSTRING_THRESHOLD, \"or more responses in a row\")\r\n  )\r\n  all_flagged_ids <- union(all_flagged_ids, \r\n                           df_main$unique_id[!df_main$unique_id %in% all_flagged_ids][step_results[[3]]$flagged])\r\n  \r\n  # Step 4: Repeated longstring check\r\n  # First calculate for all responses\r\n  step_4_condition <- longstring_n_times(select(df_main, -unique_id, -duration), \r\n                                      threshold = REPEATED_LONGSTRING_THRESHOLD)$count_longstr\r\n  total_step_4_flags <- sum(step_4_condition >= REPEATED_LONGSTRING_COUNT, na.rm = TRUE)\r\n  \r\n  # Then process for sequential filtering\r\n  step_results[[4]] <- process_step(\r\n    df = df_main[!df_main$unique_id %in% all_flagged_ids, ],\r\n    step_number = 4,\r\n    condition_fn = function(x) {\r\n      ls_counts <- longstring_n_times(select(x, -unique_id, -duration), \r\n                                      threshold = REPEATED_LONGSTRING_THRESHOLD)$count_longstr\r\n      ls_counts >= REPEATED_LONGSTRING_COUNT\r\n    },\r\n    flag_threshold = REPEATED_LONGSTRING_COUNT,\r\n    step_desc = paste(\"Had\", REPEATED_LONGSTRING_COUNT, \"or more times they straightlined at least\", \r\n                      REPEATED_LONGSTRING_THRESHOLD, \"responses in a row\")\r\n  )\r\n  all_flagged_ids <- union(all_flagged_ids, \r\n                           df_main$unique_id[!df_main$unique_id %in% all_flagged_ids][step_results[[4]]$flagged])\r\n  \r\n  # Step 5: Scale straightlining check\r\n  # First calculate for all responses\r\n  df_scales_all <- df_main\r\n  for (i in seq_along(question_sets)) {\r\n    set_name <- paste0(\"q_set_\", i)\r\n    set_columns <- question_sets[[set_name]]\r\n    df_scales_all <- calculate_longstring_ratio(df_scales_all, set_name, set_columns)\r\n  }\r\n  step_5_condition <- rowSums(select(df_scales_all, starts_with(\"q_set_\")) == 1)\r\n  total_step_5_flags <- sum(step_5_condition >= 4, na.rm = TRUE)\r\n  \r\n  # Then process for sequential filtering\r\n  df_scales_all <- df_main\r\n  for (i in seq_along(question_sets)) {\r\n    set_name <- paste0(\"q_set_\", i)\r\n    set_columns <- question_sets[[set_name]]\r\n    df_scales_all <- calculate_longstring_ratio(df_scales_all, set_name, set_columns)\r\n  }\r\n  step_5_condition <- rowSums(select(df_scales_all, starts_with(\"q_set_\")) == 1)\r\n  total_step_5_flags <- sum(step_5_condition >= SCALE_STRAIGHTLINE_THRESHOLD, na.rm = TRUE)\r\n  \r\n  # Then process for sequential filtering\r\n  step_results[[5]] <- process_step(\r\n    df = df_main[!df_main$unique_id %in% all_flagged_ids, ],\r\n    step_number = 5,\r\n    condition_fn = function(x) {\r\n      df_scales <- x\r\n      for (i in seq_along(question_sets)) {\r\n        set_name <- paste0(\"q_set_\", i)\r\n        set_columns <- question_sets[[set_name]]\r\n        df_scales <- calculate_longstring_ratio(df_scales, set_name, set_columns)\r\n      }\r\n      scale_count <- rowSums(select(df_scales, starts_with(\"q_set_\")) == 1)\r\n      scale_count >= SCALE_STRAIGHTLINE_THRESHOLD\r\n    },\r\n    flag_threshold = SCALE_STRAIGHTLINE_THRESHOLD,\r\n    step_desc = paste(\"Straightlined\", SCALE_STRAIGHTLINE_THRESHOLD, \"or more scales\")\r\n  )\r\n  all_flagged_ids <- union(all_flagged_ids, \r\n                           df_main$unique_id[!df_main$unique_id %in% all_flagged_ids][step_results[[5]]$flagged])\r\n  \r\n  # Step 6: Repetitive pattern check\r\n  # First calculate for all responses\r\n  step_6_condition <- data.frame(\r\n    unique_id = df_main$unique_id\r\n  )\r\n  \r\n  # Add columns for each pattern length\r\n  for (length in PATTERN_LENGTHS) {\r\n    col_name <- paste0(\"rp_\", length)\r\n    step_6_condition[[col_name]] <- calculate_repeated_pattern_percentage(\r\n      select(df_main, -duration), length\r\n    )\r\n  }\r\n  \r\n  # Calculate total pattern flags\r\n  pattern_cols <- paste0(\"rp_\", PATTERN_LENGTHS)\r\n  total_step_6_flags <- sum(\r\n    rowSums(step_6_condition[pattern_cols] >= PATTERN_PERCENTAGE_THRESHOLD) > 0, \r\n    na.rm = TRUE\r\n  )\r\n  \r\n  # Then process for sequential filtering\r\n  step_results[[6]] <- process_step(\r\n    df = df_main[!df_main$unique_id %in% all_flagged_ids, ],\r\n    step_number = 6,\r\n    condition_fn = function(x) {\r\n      x <- select(x, -duration)\r\n      patterns <- data.frame(\r\n        map_dfc(PATTERN_LENGTHS, function(length) {\r\n          set_names(\r\n            list(calculate_repeated_pattern_percentage(x, length)),\r\n            paste0(\"rp_\", length)\r\n          )\r\n        })\r\n      )\r\n      rowSums(patterns >= PATTERN_PERCENTAGE_THRESHOLD) > 0\r\n    },\r\n    flag_threshold = PATTERN_PERCENTAGE_THRESHOLD,\r\n    step_desc = paste0(\r\n      \"Made repetitive pattern (e.g. \",\r\n      paste(rep(LETTERS[1:PATTERN_LENGTHS[1]], 3), collapse = \"\"),\r\n      \") \", PATTERN_PERCENTAGE_THRESHOLD, \"% or more of the time\"\r\n    )\r\n  )\r\n  all_flagged_ids <- union(all_flagged_ids, \r\n                           df_main$unique_id[!df_main$unique_id %in% all_flagged_ids][step_results[[6]]$flagged])\r\n  \r\n  \r\n  # Step 7: Hours check\r\n  # First calculate for all responses\r\n  df_hours <- df %>%\r\n    select(unique_id, tmprephrs:tmcommutehrs) %>%\r\n    mutate(across(everything(), ~ as.numeric(as.character(.))))\r\n  \r\n  step_7_condition <- rowSums(select(df_hours, -unique_id), na.rm = TRUE)\r\n  total_step_7_flags <- sum(step_7_condition > MAX_WEEKLY_HOURS, na.rm = TRUE)\r\n  \r\n  # Then process for sequential filtering\r\n  step_results[[7]] <- process_step(\r\n    df = df_hours[!df_hours$unique_id %in% all_flagged_ids, ],\r\n    step_number = 7,\r\n    condition_fn = function(x) {\r\n      total_hours <- rowSums(select(x, -unique_id), na.rm = TRUE)\r\n      total_hours > MAX_WEEKLY_HOURS\r\n    },\r\n    flag_threshold = MAX_WEEKLY_HOURS,\r\n    step_desc = paste(\"Reported more than\", MAX_WEEKLY_HOURS, \r\n                      \"total hours per week across all activities\")\r\n  )\r\n  all_flagged_ids <- union(all_flagged_ids, \r\n                           df_hours$unique_id[!df_hours$unique_id %in% all_flagged_ids][step_results[[7]]$flagged])\r\n  \r\n  # Step 8: Unusual response patterns\r\n  # First calculate for all responses\r\n  df_unusual <- df %>%\r\n    select(unique_id, askquest:sameinst) %>%\r\n    mutate(across(everything(), ~ as.numeric(as.character(.)))) %>%\r\n    select(where(~!all(is.na(.))))\r\n  \r\n  step_8_condition_mahad <- calculate_mahalanobis(df_unusual)\r\n  step_8_condition_syn <- calculate_psychsyn(df_unusual)\r\n  total_step_8_flags <- sum(\r\n    (step_8_condition_mahad > MAHALANOBIS_THRESHOLD | step_8_condition_syn <= PSYCHSYN_THRESHOLD) & \r\n      !is.na(step_8_condition_mahad) & !is.na(step_8_condition_syn), \r\n    na.rm = TRUE\r\n  )\r\n  \r\n  # Then process for sequential filtering\r\n  mahad_dist <- calculate_mahalanobis(\r\n    df_unusual[!df_unusual$unique_id %in% all_flagged_ids, ]\r\n  )\r\n  syn_values <- calculate_psychsyn(\r\n    df_unusual[!df_unusual$unique_id %in% all_flagged_ids, ]\r\n  )\r\n  \r\n  step_results[[8]] <- process_step(\r\n    df = df_unusual[!df_unusual$unique_id %in% all_flagged_ids, ],\r\n    step_number = 8,\r\n    condition_fn = function(x) {\r\n      (mahad_dist > MAHALANOBIS_THRESHOLD | syn_values <= PSYCHSYN_THRESHOLD) & \r\n        !is.na(mahad_dist) & !is.na(syn_values)\r\n    },\r\n    flag_threshold = MAHALANOBIS_THRESHOLD,\r\n    step_desc = paste0(\r\n      \"Had highly unusual responses (Mahalanobis distance > \", \r\n      MAHALANOBIS_THRESHOLD,\r\n      \" or psychometric synonyms correlation <= \",\r\n      PSYCHSYN_THRESHOLD,\r\n      \")\"\r\n    )\r\n  )\r\n  all_flagged_ids <- union(all_flagged_ids, \r\n                           df_unusual$unique_id[!df_unusual$unique_id %in% all_flagged_ids][step_results[[8]]$flagged])\r\n  \r\n  # Compile final results\r\n  results$steps <- step_results\r\n  \r\n  # Store total flags for each issue\r\n  results$global_flags <- c(\r\n    total_step_1_flags,\r\n    total_step_2_flags,\r\n    total_step_3_flags,\r\n    total_step_4_flags,\r\n    total_step_5_flags,\r\n    total_step_6_flags,\r\n    total_step_7_flags,\r\n    total_step_8_flags\r\n  )\r\n  \r\n  # Create flags dataframe\r\n  flags_df <- data.frame(\r\n    unique_id = df$unique_id,\r\n    step_flagged = NA_character_\r\n  )\r\n  \r\n  # Determine which step each response was first flagged in\r\n  for (i in seq_along(step_results)) {\r\n    newly_flagged_ids <- setdiff(\r\n      if(i == 1) df$unique_id else step_results[[i-1]]$remaining_ids,\r\n      step_results[[i]]$remaining_ids\r\n    )\r\n    flags_df$step_flagged[flags_df$unique_id %in% newly_flagged_ids] <- \r\n      step_results[[i]]$step_desc\r\n  }\r\n  \r\n  \r\n  # Create flag columns based on the initial calculations for each issue\r\n  flag_columns <- data.frame(unique_id = df$unique_id)\r\n  \r\n  # Duration flags\r\n  flag_columns[[paste(\"Flag: Completed survey in\", DURATION_THRESHOLD_MIN, \"minutes or less\")]] <- \r\n    df_main$duration <= DURATION_THRESHOLD_MIN & !is.na(df_main$duration)\r\n  \r\n  # Missing values flags\r\n  flag_columns[[paste(\"Flag: More than\", MISSING_THRESHOLD_PCT, \"% of survey questions missing\")]] <- \r\n    rowSums(is.na(df_for_missing)) / ncol(df_for_missing) * 100 > MISSING_THRESHOLD_PCT\r\n  \r\n  # Longstring flags\r\n  flag_columns[[paste(\"Flag: Straightlined\", LONGSTRING_THRESHOLD, \"or more responses in a row\")]] <- \r\n    step_3_condition >= LONGSTRING_THRESHOLD\r\n  \r\n  # Repeated longstring flags\r\n  flag_columns[[paste(\"Flag: Had\", REPEATED_LONGSTRING_COUNT, \"or more longstrings of\", \r\n                      REPEATED_LONGSTRING_THRESHOLD, \"or more responses\")]] <- \r\n    step_4_condition >= REPEATED_LONGSTRING_COUNT\r\n  \r\n  # Scale straightlining flags\r\n  flag_columns[[paste(\"Flag: Straightlined\", SCALE_STRAIGHTLINE_THRESHOLD, \"or more scales\")]] <- \r\n    step_5_condition >= SCALE_STRAIGHTLINE_THRESHOLD\r\n  \r\n  # Repetitive pattern flags\r\n  flag_columns[[paste0(\r\n    \"Flag: Made repetitive pattern \", \r\n    PATTERN_PERCENTAGE_THRESHOLD, \r\n    \"% or more of the time\"\r\n  )]] <- \r\n    rowSums(step_6_condition[pattern_cols] >= PATTERN_PERCENTAGE_THRESHOLD) > 0\r\n  \r\n  # Hours flags\r\n  flag_columns[[paste(\"Flag: Reported more than\", MAX_WEEKLY_HOURS, \r\n                      \"total hours per week\")]] <- \r\n    step_7_condition > MAX_WEEKLY_HOURS\r\n  \r\n  # Unusual response flags\r\n  flag_columns[[paste0(\r\n    \"Flag: Unusual response patterns (Mahalanobis > \", \r\n    MAHALANOBIS_THRESHOLD,\r\n    \" or synonyms <= \",\r\n    PSYCHSYN_THRESHOLD,\r\n    \")\"\r\n  )]] <- \r\n    (step_8_condition_mahad > MAHALANOBIS_THRESHOLD | step_8_condition_syn <= PSYCHSYN_THRESHOLD) & \r\n    !is.na(step_8_condition_mahad) & !is.na(step_8_condition_syn)\r\n  \r\n  # Convert TRUE/FALSE to Yes/No\r\n  flag_columns <- flag_columns %>%\r\n    mutate(across(starts_with(\"Flag:\"), ~ifelse(., \"Yes\", \"No\")))\r\n  \r\n  # Then modify df_result creation:\r\n  df_result <- df %>%\r\n    left_join(flags_df, by = \"unique_id\") %>%\r\n    left_join(flag_columns, by = \"unique_id\") %>%\r\n    mutate(\r\n      `Flagged for Low Effort?` = ifelse(!is.na(step_flagged), \"Yes\", \"No\"),\r\n      `Reason for Flag` = step_flagged\r\n    ) %>%\r\n    select(`Flagged for Low Effort?`, `Reason for Flag`, \r\n           starts_with(\"Flag:\"), everything(), -step_flagged)\r\n  \r\n  return(list(\r\n    data = df_result,\r\n    flags = results$global_flags,\r\n    step_results = step_results\r\n  ))\r\n}\r\n\r\n# Function to calculate summary\r\ncalculate_summary <- function(processed_data, global_flags, step_results) {\r\n  # Create summary dataframe\r\n  summary_df <- tibble(\r\n    `Step Description` = c(\r\n      \"Initial Number of Survey Responses\",  # First row\r\n      \"Raw Dataset\",\r\n      sapply(step_results, function(x) x$step_desc)\r\n    ),\r\n    `Remaining Unflagged Responses` = c(\r\n      nrow(processed_data),  # Starting count\r\n      nrow(processed_data),\r\n      sapply(step_results, function(x) length(x$remaining_ids))\r\n    ),\r\n    `Responses Flagged in this Step` = c(\r\n      NA_integer_,  # Blank for first row\r\n      0,\r\n      sapply(seq_along(step_results), function(i) {\r\n        if (i == 1) {\r\n          length(setdiff(processed_data$unique_id, step_results[[i]]$remaining_ids))\r\n        } else {\r\n          length(setdiff(\r\n            step_results[[i-1]]$remaining_ids,\r\n            step_results[[i]]$remaining_ids\r\n          ))\r\n        }\r\n      })\r\n    )\r\n  )\r\n  \r\n  # Add percentage columns\r\n  summary_df <- summary_df %>%\r\n    mutate(\r\n      `Percent of All Responses Flagged in this Step` = \r\n        `Responses Flagged in this Step` / nrow(processed_data),\r\n      `Total Responses Flagged for this Issue` = \r\n        c(NA_integer_, 0, unname(global_flags)),\r\n      `Percent of All Responses with this Issue` = \r\n        scales::percent(`Total Responses Flagged for this Issue` / nrow(processed_data), \r\n                        accuracy = 0.1, na.rm = TRUE)\r\n    )\r\n  \r\n  # Number the steps (skip first two rows)\r\n  summary_df$`Step Description`[3:nrow(summary_df)] <- paste0(\r\n    \"Step \", 1:(nrow(summary_df)-2), \": \", \r\n    summary_df$`Step Description`[3:nrow(summary_df)]\r\n  )\r\n  \r\n  # Add final summary row\r\n  total_flagged <- sum(summary_df$`Responses Flagged in this Step`, na.rm = TRUE)\r\n  total_percentage <- total_flagged / nrow(processed_data)\r\n  \r\n  summary_df <- summary_df %>%\r\n    bind_rows(\r\n      tibble(\r\n        `Step Description` = \"Final Summary of All Steps\",\r\n        `Remaining Unflagged Responses` = nrow(processed_data) - total_flagged,\r\n        `Responses Flagged in this Step` = total_flagged,\r\n        `Percent of All Responses Flagged in this Step` = total_percentage,\r\n        `Total Responses Flagged for this Issue` = NA_integer_,\r\n        `Percent of All Responses with this Issue` = NA_character_\r\n      )\r\n    )\r\n  \r\n  return(summary_df)\r\n}\r\n\r\n# Function to show NSSE upload instructions\r\nshow_upload_instructions <- function(session) {\r\n  showModal(modalDialog(\r\n    title = \"NSSE Data Upload Instructions\",\r\n    \"For the National Survey of Student Engagement (NSSE), you can upload the raw data file in either .sav (SPSS), .csv, or .xlsx format. IMPORTANT: Make sure to upload the raw data file exactly as it was sent by NSSE (i.e. no edits).\",\r\n    easyClose = TRUE,\r\n    footer = modalButton(\"OK\")\r\n  ))\r\n}\r\n","type":"text"}]
